비행기 이착륙 지연 데이터를 받을건데요<br>
저번에 제가 쉘스크립트 언급한적이 있잖아요?<br>
책에서 반복문을 통해서 알아서 다운로드 받고 압축을 푸는 쉘스크립트를 써뒀더라구요.<br>
책에는 여기에 받으세요~ 했는데 우리는 다른데 저장합시다.<br>
<color4>hadoop-examples</color4> 폴더에 <color4>airplain</color4> 이라는 폴더를 만들어주세요.<br>
그리고 <color4>airplain</color4> 폴더에 <color4>download.sh</color4> 라는 파일을 만들고 내용을 아래처럼 입력해주세요.<br>

<terminal>
<blur><i>#! /bin/sh</i></blur>

<color4>for</color4> <color7>((</color7>i = <color2>1987</color2> <color7>; i</color7> <= <color2>2008</color2> <color7>; i</color7>++<color7>))</color7> <color4>do</color4>
    wget http://stat-computing.org/dataexpo/2009/$i.csv.bz2
    bzip2 -d $i.csv.bz2
    sed -e <color7>'1d'</color7> $i.csv > $i_temp.csv
    mv $i_temp.csv $i.csv
<color4>done</color4>
</terminal>

첫줄에 <blur><i>#! /bin/sh</i></blur> 은 쉘스크립트 라고 하는 주석 선언문입니다.<br>
for 문은 다들 좀 친숙하시죠? 1989년도 데이터부터 2008년도 데이터까지 받겠다는 의미입니다.<br>
<color4>$i</color4> 는 아마도 파이썬이나 루비에서 <color4>{$i}</color4> 하고 변수를 입력하는 의미인가봅니다.<br>
다운받고, 압축 풀고, sed -e 는 파일의 다중편집 명령어입니다. 파일 안에 '1d' 라는 단어가 temp가 더 적으면 temp를 $i로 바꾸라는 명령어입니다.<br>
사실 뭔지 잘 모르겠습니다. bz2 파일 안에 2008.csv 와 2008_temp.csv 파일이 같이 있는데 비교하는 것 같습니다.<br>
쨋든 작가가 친절하게 써놨으니 그냥 이렇게 해보죠.<br>
일단 터미널로 해당 폴더 경로로 들어가주세요... 아니 그냥 제가 밑에 써드릴게요.<br>

<terminal>
<strong>[hadoop@namenode ~]$</strong> cd /home/hadoop/hadoop-examples/airplain
<strong>[hadoop@namenode airplain]$</strong> sudo chmod -R 777 download.sh
<strong>[hadoop@namenode airplain]$</strong> ./download.sh
</terminal>

다 받는데 좀 걸릴겁니다.<br>
한 30분 쉬고오시죠 ^^;<br>
<br>
다 되고나면 다운로드 받은 파일을 HDFS로 옮겨야 합니다.<br>

<terminal>
<strong>[hadoop@namenode ~]$</strong> cd $HADOOP_HOME
</terminal>

혹시나 이렇게 했는데 하둡 폴더로 가지 않으면 <color4>source /etc/profile</color4> 하고 한번 입력해주세요.<br>

<terminal>
<strong>[hadoop@namenode ~]$</strong> cd $HADOOP_HOME
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -mkdir airplain
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -put /home/hadoop/hadoop-examples/airplain/*.csv airplain
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -ls airplain

</terminal>

복사를 마쳤으니 이제 분석할 코드를 구현해봅시다.<br>
라고 하고 책을 들여다보니 콤마를 기준으로 배열로 쪼개던데 저 .cvs 파일에 뭐가 들었는지도 모르고 앵무새마냥 따라 코드를 입력하는건 의미없는 것 같으니<br>
.csv 파일을 한번 열어서 뭔지 살펴보겠습니다.<br>

<img src="/hadoop/img2/3_1.jpg" alt="">

파일들이 콤마 단위로 테이블화 되어있는것을 확인할 수 있습니다.<br>
각각이 뭔지 하나씩 보겠습니다. 배열로 인식하여 쓰도록 하겠습니다. 첫번째 컬럼은 [0] 이런식으로요.<br>
<br>
[0] : 년도 입니다.<br>
[1] : 월 입니다.<br>
[2] : 일 입니다.<br>
[3] : ??뭔지 모르겠습니다. 10 이하의 숫자가 쓰여져 있는데 짐작이 안가네요.<br>
[4] : ?? 700대의 숫자가 쓰여있습니다.....이것과 아래 3개 중 뭔가가 승객 수 일 것 같네요.<br>
[5] : ?? 700대의 숫자가 쓰여있습니다.<br>
[6] : ?? 900대의 근접한 숫자가 쓰여있습니다.<br>
[7] : ?? 800대의 숫자가 쓰여있습니다.<br>
[8] : PS...?? 항공사 코드라고 합니다.<br>
[9] : 1451....?? 경로 번호?<br>
[10] : NA.....??<br>
[11] : 70 ~ 90 대의 숫자가 쓰여있습니다.<br>
[12] : 70 ~ 90 대의 숫자가 쓰여있습니다.<br>
[13] : NA.....??<br>
[14] : 양수 일 때도 있고 음수 일 떄도 있고....?? 도착 지연시간이라고 합니다. 양수는 지연, 음수는 빨리 도착한건가?<br>
[15] : 양수 일 때도 있고 음수 일 떄도 있고....?? 출발 지연시간이라고 합니다. 양수는 지연, 음수는 빨리 출발한건가?<br>
[16] : SAN...도착지?<br>
[17] : SFO...출발지?<br>
[18] : 447....운항거리 라고 합니다..<br>
[19] : NA.....??<br>
[20] : NA.....??<br>
[21] : 0<br>
[22] : NA.....??<br>
[23] : 0<br>
[24] : NA.....??<br>
[25] : NA.....??<br>
[26] : NA.....??<br>
[27] : NA.....??<br>
[28] : NA.....??<br>
<br>
일단 책에 나와있는 코드와 이걸 대조했을 때 우리가 정확히 알아낼 수 있는건<br>
[0] 년도, [1] 월, [2] 일, [8] 항공사 코드, [14] 도착 지연시간, [15] 출발 지연시간, [16] 도착지?, [17] 출발지? [18] 운항거리<br>
이렇게 알 수 있습니다.<br>
<br>
알아냈으니 책에 나와있는대로가 아닌 제 입맛대로 코드를 바꿔서 짜보도록 하겠습니다.<br>
아는 정보는 다 출력해내도록 하죠.<br>
공통 클래스를 구현한다고 하는데 이쪽이 조금 편해보이는 느낌이긴 합니다.<br>
공통 클래스를 먼저 작성해보죠. 저는 책이랑 조금 다르게 코드를 짤겁니다. 파일 이름도 다를거구요.<br>
아, 그리고 이번 예제를 미리 훑어보고 알게된 점은, key - value 설정이라고 해서 딱 하나의 값만 담을 수 있는게 아니라<br>
key 안에 여러 값을 담을 수 있다는 것 입니다.<br>
<br>
그리고, 미리 뒤의 내용을 보고, 다수의 파일 출력 코드를 작성해보도록 하겠습니다.<br>
<br>
<color4>AirlineMapper.java</color4>

<terminal>
import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class AirlineMapper extends Mapper&lt;LongWritable, Text, Text, IntWritable&gt; {

    private IntWritable outputValue = new IntWritable(1);
    private Text outputKey = new Text();

    public void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {

        String[] column = value.toString().split(",");

        // 년, 월, 일, 항공사 코드, 출발지, 도착지, count

        if (!column[15].equals("NA") && Integer.parseInt(column[15]) > 0) {  // 출발 지연일 때
            outputKey.set("D" + "," + Integer.parseInt(column[0]) + "," + Integer.parseInt(column[1]) + "," + column[17]);
            context.write(outputKey, outputValue);
        } else if (!column[14].equals("NA") && Integer.parseInt(column[14]) > 0) {  // 도착 지연일 때
            outputKey.set("A" + "," + Integer.parseInt(column[0]) + "," + Integer.parseInt(column[1]) + "," + column[17]);
            context.write(outputKey, outputValue);
        }
    }
}
</terminal>

<color4>AirlineReducer.java</color4>

<terminal>
import java.io.IOException;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;

public class AirlineReducer extends Reducer&lt;Text, IntWritable, Text, IntWritable&gt; {
    private MultipleOutputs&lt;Text, IntWritable&gt; mos;
    private Text outputKey = new Text();
    private IntWritable result = new IntWritable();

    @Override
    public void setup(Context context) throws IOException, InterruptedException {
        mos = new MultipleOutputs&lt;Text, IntWritable&gt;(context);
    }

    public void reduce(Text key, Iterable&lt;IntWritable&gt; values, Context context) throws IOException, InterruptedException {
        String[] column = key.toString().split(",");
        outputKey.set(column[1] + "\t" + column[2] + "\t" + column[3] + "\t" + column[4] + "\t" + column[5] + "\t" + column[6]);

        if (column[0].equals("D")) {  // 출발 지연
            int sum = 0;
            for (IntWritable value : values) {
                sum += value.get();
            }
            result.set(sum);
            mos.write("departure", outputKey, result);
        } else {    // 도착 지연
            int sum = 0;
            for (IntWritable value : values) {
                sum += value.get();
            }
            result.set(sum);
            mos.write("arrival", outputKey, result);
        }
    }

    @Override
    public void cleanup(Context context) throws IOException, InterruptedException {
        mos.close();
    }
}
</terminal>

<color4>AirlineCount.java</color4>

<terminal>
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.conf.Configured;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.TextInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.TextOutputFormat;
import org.apache.hadoop.util.GenericOptionsParser;
import org.apache.hadoop.util.Tool;
import org.apache.hadoop.util.ToolRunner;
import org.apache.hadoop.mapreduce.lib.output.MultipleOutputs;

public class AirlineCount extends Configured implements Tool {

    public static void main(String[] args) throws Exception {
        int res = ToolRunner.run(new Configuration(), new AirlineCount(), args);
        System.out.println("MR-Job Result : " + res);
    }

    public int run(String[] args) throws Exception {

        if (args.length != 2) {
            System.err.println("Usage: AirlineCount &lt;input&gt; &lt;output&gt;");
            System.exit(2);
        }

        Job job = new Job(getConf(), "AirlineCount");
        job.setJarByClass(AirlineCount.class);
        job.setMapperClass(AirlineMapper.class);
        job.setReducerClass(AirlineReducer.class);

        job.setInputFormatClass(TextInputFormat.class);
	job.setOutputFormatClass(TextOutputFormat.class);

	job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        FileInputFormat.addInputPath(job, new Path(args[0]));
	FileOutputFormat.setOutputPath(job, new Path(args[1]));
        
        MultipleOutputs.addNamedOutput(job, "departure", TextOutputFormat.class, Text.class, IntWritable.class);
        MultipleOutputs.addNamedOutput(job, "arrival", TextOutputFormat.class, Text.class, IntWritable.class);

        job.waitForCompletion(true);
        return 0;
    }
}
</terminal>

다 했으면 컴파일을 합니다.<br>

<terminal>
<strong>[hadoop@namenode airplain]$</strong> javac -cp $HADOOP_HOME/hadoop-core-1.2.1.jar Airline*.java
<strong>[hadoop@namenode airplain]$</strong> jar -cvf $HADOOP_HOME/AirlineCount.jar Airline*.class
<strong>[hadoop@namenode airplain]$</strong> cd $HADOOP_HOME
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop jar AirlineCount.jar AirlineCount airplain delay_count_mos
</terminal>

이번거는 인내심을 가지고 좀 기다리셔야 합니다.<br>
나름 12GB인데 몇십초만에 되진 않거든요.<br>
<br>
다 되고나면 아래 명령어를 입력해주세요.<br>

<terminal>
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -get airplain/departure-r-00000 departure.txt
<strong>[hadoop@namenode hadoop]$</strong> ./bin/hadoop fs -get airplain/arrival-r-00000 arrival.txt
<strong>[hadoop@namenode hadoop]$</strong> mv departure.txt /home/hadoop/hadoop-examples/airplain/
<strong>[hadoop@namenode hadoop]$</strong> mv arrival.txt /home/hadoop/hadoop-examples/airplain/
<strong>[hadoop@namenode hadoop]$</strong> cd /home/hadoop/hadoop-examples/airplain/
<strong>[hadoop@namenode airplain]$</strong>
</terminal>

이제 시각화를 진행해봅시다.<br>
터미널에서 R을 실행시켜 진행해보죠.<br>

<terminal>
<strong>[hadoop@namenode airplain]$</strong> R

> library(ggplot2)
> library(dplyr)
> arrival = read.table("arrival.txt", header = FALSE, sep = "", col.names = c("year", "month", "day", "codename", "departure", "arrival", "count"))
> arrival
</terminal>
